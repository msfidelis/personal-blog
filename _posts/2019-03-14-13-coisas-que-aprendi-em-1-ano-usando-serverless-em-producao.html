---
layout: post
title: 13 coisas que aprendi em 1 ano usando Serverless em produÃ§Ã£o
canonical_url: https://medium.com/@fidelissauro/13-coisas-que-aprendi-em-1-ano-usando-serverless-em-produ%C3%A7%C3%A3o-40e4e5e50470?source=rss-fc2fda5e9bc2------2
---

<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*D55D8ZOM94QZ-E3G4NftjQ.jpeg" /><figcaption>Photo by <a href="https://unsplash.com/photos/m-VhHYQ4yFg?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Nazarii Yurkov</a> onÂ <a href="https://unsplash.com/search/photos/builder?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p>O objetivo desse artigo Ã© mostrar uma sÃ©rie de aprendizados e dicas de alguÃ©m precisou escalar meia dÃºzia de funÃ§Ãµes lambda criadas pra pequenas automaÃ§Ãµes de infraestrutura, tarefas agendadas, resposta automÃ¡tica pra alertas atÃ© equipes grandes de produtos inteiramente construÃ­dos utilizando Serverless por meio de FaaS com AWS Lambda, mas essas dicas podem ser absorvidas por qualquer um que seja o vendor que vocÃª estiver utilizando.</p><p>Sempre tive curiosidade pela adoÃ§Ã£o de tecnologias Serverless na resoluÃ§Ã£o de problemas, e desde o primeiro contato sempre busquei formas de trazer a utilizaÃ§Ã£o desse tipo de tecnologia pro meu dia a dia. Aqui vai o meu compiladÃ£o com as principais dicas que eu gostaria que alguÃ©m tivesse me dado quando comecei a desbravar esse tipo de arquitetura.</p><h3>1. Use um orquestrador, e se possÃ­vel o Serverless Framework</h3><p>A primeira apresentaÃ§Ã£o que tive com o AWS Lambda me mostrou uma abordagem simplista de â€œgerar zipzinhosâ€ com seu cÃ³digo, selecionar um runtime da sua linguagem, e botar pra rodar. Depois criar um endpointzinho na mÃ£o no API Gateway e integrar naquela Lambda e pÃ¡. Tenho um Hello World â€œsem servidorâ€. A primeira dÃºvida, de quem veio de equipes de desenvolvimento de ERP e SaaS Ã© â€œBeleza, mas nÃ£o da pra usar no dia a diaâ€. Com 10, 20, 30 funÃ§Ãµes, em uma equipe mais dinÃ¢mica de desenvolvimento essa rotina do build do â€œzipzinhoâ€ e configuraÃ§Ãµes manuais se torna impraticÃ¡vel.</p><p>Utilizar um orquestrador via CLI faz com que seja possÃ­vel integrar seu deploy, multistage, testes a qualquer pipeline de entrega contÃ­nua, e ele cobre muita configuraÃ§Ã£o manual que vocÃª teria que executar conforme sua aplicaÃ§Ã£o e equipeÂ escalam.</p><p>Existem vÃ¡rios tipos de orquestradores, o meu favorito Ã© a figurinha carimbada do assunto, o <strong>Serverless Framework</strong>.</p><p>O <strong>Serverless Framework</strong> cobre vÃ¡rios vendors de mercado como <strong>Google Cloud</strong>, <strong>Azure</strong>, <strong>IBM</strong>, <strong>Fn</strong> e o que nÃ³s usamos, o saudoso <strong>AWSÂ Lambda</strong>.</p><p><a href="https://serverless.com">Serverless - The Serverless Application Framework powered by AWS Lambda, API Gateway, and more</a></p><h3>2. Use/Crie um boilerplate deÂ projeto</h3><p>Quando vocÃª trabalha sozinho assuntos como organizaÃ§Ã£o, padronizaÃ§Ã£o e reaproveitamento de cÃ³digo nÃ£o sÃ£o coisas tÃ£o importantes assim. Quando vocÃª precisa escalar esse tipo de tecnologia pra um ou mais times de desenvolvimento, Ã© necessÃ¡rio existir um consenso de padrÃµes e boas prÃ¡ticas, e tambÃ©m de um centralizador de bibliotecas. Afinal Ã© inviÃ¡vel ficar replicando modificaÃ§Ãµes incrementais, correÃ§Ãµes bugs em 20, 30 versÃµes diferentes da mesma biblioteca. Por isso crie uma estruturaÃ§Ã£o minima de cÃ³digo para seus projetos. Nossa proposta de organizaÃ§Ã£o e estruturaÃ§Ã£o estÃ¡ pÃºblica e open source. Esse boilerplate Ã© utilizado desde os pequenos atÃ© os grandes projetos, e ele tambÃ©m estÃ¡ lÃ¡ no <a href="https://github.com/serverless/serverless#v1-projects"><strong>README</strong></a> oficial do Serverless Framework doÂ Github.</p><p><a href="https://github.com/msfidelis/serverless-architecture-boilerplate">msfidelis/serverless-architecture-boilerplate</a></p><h3>3. Testes, eles precisam existir aquiÂ tambÃ©m</h3><p>Mais um ponto crucial da velha escola que precisamos adotar dentro desse novo paradigma. AplicaÃ§Ãµes construÃ­das sobre arquiteturas Serverless sÃ£o naturalmente muito difÃ­ceis de serem testados por normalmente consumirem muitos recursos vendor como filas do SQS, Streams do Kinesis, Tabelas do Dynamo, Buckets do S3 eÂ etc.</p><p>No caso, utilizamos 100% de NodeJS em nossos projetos, e aproveitamos a maravilhosa stack de testes que o Javascript nos provÃª via comunidade. No caso utilizamos:</p><p><a href="https://mochajs.org"><strong>Mocha</strong></a>â€Šâ€”â€ŠLib de testes unitÃ¡rios e integraÃ§Ã£o<br><a href="https://www.chaijs.com"><strong>Chai</strong></a>â€Šâ€”â€ŠLib de Assertation / Expectation para TDD eÂ BDD</p><p>TambÃ©m Ã© possÃ­vel utilizar o o <a href="https://github.com/hapijs/lab"><strong>Lab</strong></a> da Hapi caso seja de sua preferÃªncia.</p><p>O teste de funÃ§Ãµes lambda seguem um padrÃ£o atÃ© que simples. Normalmente a AWS injeta uma funÃ§Ã£o de callbackÂ , na qual normalmente usamos para encerrar a execuÃ§Ã£o da mesma. O segredo Ã© que vamos injetar essa funÃ§Ã£o de callback nas funÃ§Ãµes que queremos testar e fazer os assertations doÂ retorno.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/982/0*i3wi9ky3HEcwJr5C" /></figure><h3>4. Seu Cloud rodandoÂ local</h3><p>Ã‰ necessÃ¡rio que seus desenvolvedores consigam simular localmente alguns recursos especificos da nÃºvem que vocÃª estÃ¡ utilizando. No nosso caso, usamos em peso vÃ¡rios serviÃ§os fornecidos pela AWS. Para diminuir a diferenÃ§a entre os ambiente de desenvolvimento local com os ambientes de homolaÃ§Ã£o, produÃ§Ã£o e etc, serÃ¡ necessÃ¡rio conseguir utilizar alguns desses principais serviÃ§os localmente.</p><p>Adotamos algumas estratÃ©gias matadoras pra resolver esse problema;</p><ol><li>O Plugin Serverless Offline;</li><li>Muito Docker;</li><li>Plugins e mais plugins da comunidade;</li></ol><p>Atraves do <strong>serverless-offline</strong>, plugin do Serverless Framework, conseguimos realizar chamadas de API localmente, diretamente pela portaÂ 3000</p><pre>serverless offline start --stage local</pre><ul><li><a href="https://github.com/dherault/serverless-offline">dherault/serverless-offline</a></li><li><a href="https://github.com/msfidelis/serverless-offline-sqs-esmq">msfidelis/serverless-offline-sqs-esmq</a></li><li><a href="https://github.com/ajmath/serverless-offline-scheduler">ajmath/serverless-offline-scheduler</a></li><li><a href="https://github.com/svdgraaf/serverless-pseudo-parameters">svdgraaf/serverless-pseudo-parameters</a></li></ul><p>Rodamos o Serverless Offline via Docker tambÃ©m. Tentamos conteinerizar tanto o ambiente do serverless offline quanto as dependÃªncias de infraestrutura mockada daÂ AWS:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/df82b3f5df8704630695ebfcd429f381/href">https://medium.com/media/df82b3f5df8704630695ebfcd429f381/href</a></iframe><p>Separamos nossos outros serviÃ§os da AWS emulados localmente em outros containers, quando isso cresce demais, utilizamos o Localstack. AtÃ© o numero de containers virar um problema, gostamos de separarÂ tudo.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/cc7d0a456cc3b2de93417f375f1f451e/href">https://medium.com/media/cc7d0a456cc3b2de93417f375f1f451e/href</a></iframe><p>Segue alguns recursos que usamos pra mockar localmente a infra daÂ AWS.</p><ul><li><a href="https://github.com/localstack/localstack">GitHub - localstack/localstack: ğŸ’» A fully functional local AWS cloud stack. Develop and test your cloud &amp; Serverless apps offline</a></li><li><a href="https://www.npmjs.com/package/serverless-dynamodb-local">serverless-dynamodb-local</a></li><li><a href="https://www.npmjs.com/package/serverless-s3-local">serverless-s3-local</a></li><li><a href="https://github.com/softwaremill/elasticmq">softwaremill/elasticmq</a></li></ul><h3>5. AplicaÃ§Ã£o de verdade, roda emÂ VPC</h3><p>Um dos critÃ©rios mais importantes para criar aplicaÃ§Ãµes de verdade, robustas e seguras na AWS, serÃ¡ necessÃ¡rio ir alÃ©m do bÃ¡sico dentro das configuraÃ§Ãµes de rede. Ou seja, precisaremos gastar um tempo projetando a rede interna do nossa aplicaÃ§Ã£o.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/22c89a54a83e41067e7c20df245d9567/href">https://medium.com/media/22c89a54a83e41067e7c20df245d9567/href</a></iframe><h4>Segue algumas dicas importantes:</h4><ul><li>Escolha pelo menos duas zonas de disponibilidade. Isso vai garantir uma redundÃ¢ncia caso o serviÃ§o do lambda venha a falhar em algumaÂ delas.</li><li>Cada zona de disponibilidade deverÃ¡ ter no mÃ­nimo uma subnet publica e uma privada para rodar a aplicaÃ§Ã£o. Isso garante o trÃ¡fego pra internet e o isolamento de execuÃ§Ã£o das funÃ§Ãµes daÂ DMZ.</li><li>As lambdas deverÃ£o ser configuradas para rodar somente nas subnets privadas. Sempre.</li><li>Crie mais uma subnet em cada AZ sem acesso a internet para fazer deploy dos bancos de dados SQL, <strong>Redis</strong>, <strong>Memcached</strong>, <strong>Elasticsearch</strong> e derivados. Isso te garante uma camada a mais de seguranÃ§a e isolamento de recursos.</li><li>Crie um<strong> NAT Gateway</strong> com IP fixo em uma das subnets pÃºblicas, e faÃ§a o roteamento das <strong>Route Tables</strong> de todo o trÃ¡fego das subnets privadas para o NAT Gatewayâ€Šâ€”â€ŠIsso Ã© importante, porque assim todas as requisiÃ§Ãµes vÃ£o sair pra internet sempre com o mesmo IP. Uma hora ou outra vocÃª vai se deparar com algum vendor, parceiro e etc que vai necessitar de um IP fixo do seu lado pra alguma liberaÃ§Ã£o, e vai te poupar um estresse do tipo &quot;<em>COMO QUE EU VOU FAZER LAMBDA TER IP FIXO, OS CARA TA DOIDO</em>&quot;. Ã‰ possivel, e mais fÃ¡cil resolver isso logo deÂ cara.</li><li>Crie sempre suas subnets privadas com uma mÃ¡scara de subnet baixa. Isso vai garantir uma quantidade significativa de IP&#39;s disponiveis. A quantidade de lambdas em execuÃ§Ã£o vai se limitar pelo nÃºmero de IP&#39;s disponiveis entre as subnets indicadas pra elas rodarem. Normalmente as subnets de aplicaÃ§Ã£o, fazemos deploy com a notaÃ§Ã£o /20, isso nos dÃ¡ em torno de <strong>4094</strong> IP&#39;s em cada subnet para execuÃ§Ã£o de lambdas. Da pra escalar bastante. Nas auxiliares fazemos o deploy com a notaÃ§Ã£o padrÃ£o/24 mesmo.</li></ul><h3>6. SeguranÃ§a naÂ AWS</h3><p>PadrÃµes de Firewall, monitoramento e seguranÃ§a sÃ£o necessÃ¡rios pra garantir a estabilidade de uma aplicaÃ§Ã£o, esteja seguindo qualquer padrÃ£o quer seja. Existem vÃ¡rias soluÃ§Ãµes de firewall e CDN no mercado pra que vocÃª consiga colocar na frente da sua API ou aplicaÃ§Ã£o. No nosso caso adotamos uma arquitetura bacana utilizando CloudFront na frente da nossaÂ API.</p><p>Mas CloudFront?? CDN? Cache?? Na frente de umaÂ API??</p><p>Sim. Utilizamos o Cloudfront, mas sem cachear nada, passando todo o conteÃºdo para a origem. Mas pra que isso? Simples! O AWSÂ WAF.</p><p>AtÃ© o presente momento, ainda nÃ£o Ã© possÃ­vel anexar regras do AWS WAF diretamente do API Gateway em todas as regiÃµes. Dos nossos serviÃ§os, sÃ³ anexamos diretamente no que estÃ¡ rodando na Virginia. Nas demais localizaÃ§Ãµes aproveitamos essa arquitetura. Por enquanto.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/527/1*8iJi3vOdjQ6U7xmY2xDyxQ.png" /></figure><p>Normalmente redirecionamos os logs das nossas regras do WAF pra um Stream do Kinesis e em seguida direcionamos para um cluster de Elasticsearch pra anÃ¡lise e monitoramento.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*SptdrbfChM3Tf8TjFfbVvw.png" /></figure><h3>7. Bancos SQL sÃ£o possÃ­veis!</h3><p>Na maioria dos exemplos que encontramos sobre Serverless, em 200% sÃ³ se fala no querido <strong>DynamoDB</strong>. Mas essa realidade de persistÃªncia de dados pode ser estendida ao bom e velho SQL se necessÃ¡rio, abrindo o leque pra bancos <strong>MySQL</strong>, <strong>MariaDB</strong>, <strong>PostgreSQL</strong>, <strong>SQL Server</strong>, <strong>Oracle</strong> e etc. PorÃ©m sÃ£o necessÃ¡rios alguns pontos deÂ atenÃ§Ã£o:</p><ol><li>Sua aplicaÃ§Ã£o deverÃ¡ estar rodando dentro de um contexto deÂ VPC</li><li>SerÃ¡ necessÃ¡rio anexar uma security group a execuÃ§Ã£o das suas funÃ§ÃµesÂ lambda</li><li>Esse security group dos runtimes deverÃ£o estar autorizados na porta do serviÃ§o do banco de dados, seja ele RDS ou nÃ£o. Caso esteja utilizando um banco de dados em algum outro lugar, autorize o IP de saÃ­da da sua rede. Lembra que eu te falei que vai ser importante a qualquerÂ momento?</li><li>Cuidado com o pool de conexÃµes, talvez dÃª ruim e seu banco venha a ficar indisponÃ­vel dependendo do throughput das suas funÃ§ÃµesÂ lambda.</li></ol><h3>8. Bancos NoSQL, Memory Cache, Storage sÃ£o seus melhoresÂ amigos</h3><p>FaÃ§a muito uso de recursos como o <strong>DynamoDB</strong> pra escalar escrita e leitura em lotes. MasÂ cuidado!</p><p>Use muito memory cache como clusters de <strong>Redis</strong> e <strong>Memcached</strong> para tirar carga dos bancos de dados. No caso do DynamoDB, pode ficar caro escalar muito Write / Read com muita frequÃªncia, e os bancos SQL, bom, da velha escola, eles sÃ£o sempre o gargalo maisÂ chato.</p><p>EntÃ£o use a abuse da velha escola de arquitetura pra esse novo paradigma. Muita coisa pode ser reaproveitada e atÃ© melhorada nesse novo contexto de desenvolvimento.</p><h3>9. Entregue tudo por umaÂ Pipeline</h3><p>Mesmo com um orquestrador, ainda existem problemas a serem lidados com escala de times e deploys diÃ¡rios. O ideal Ã© manter o produto sendo entregue sempre por uma pipeline de entrega continua, onde vocÃª vai garantir a estabilidade e qualidade o seu cÃ³digo serverless pra qualquer stage que vocÃª estiver trabalhando.</p><p>O que podemos incluir numa pipeline pra ajudar a garantir os padrÃµes de qualidade que eu necessito no meu projeto em Serverless? Segue uma listinha:</p><ul><li>Testes unitÃ¡rios e de integraÃ§Ã£o (Mocha, Chai,Â Lab)</li><li>Syntax Check &amp; Design Patterns (jslint, jshint, standard)</li><li>DocumentaÃ§Ã£o &amp; GMUD (Pra processos mais burocrÃ¡ticos)</li><li>SeguranÃ§a (npm audit, SourceClear, retire.js, arachni)</li></ul><p>VocÃª pode utilizar o que vocÃª quiser, existem Ã³timas opÃ§Ãµes de mercado e Open Source como <strong>CircleCI</strong>, <strong>CodeShip</strong>, <strong>Jenkins</strong> e etc. Aqui entregamos todos os nosso produtos e funÃ§Ãµes auxiliares por meio da stack do <strong>CodePipeline</strong> da AWS. Motivo? Podemos entregar desde o projeto mais simples atÃ© os mais complexos com a mesma ferramenta. Normalmente adicionamos os steps de build em um arquivo `buildspec.yml`.</p><p>Segue umÂ exemplo:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c6453f2c9ae3146c605ccb5cc35e3f5e/href">https://medium.com/media/c6453f2c9ae3146c605ccb5cc35e3f5e/href</a></iframe><p>Utilizamos nosso orquestrador via CLI pra automatizar uma entrega de cÃ³digo continua em produÃ§Ã£o.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*_XnytMmb7WIZRyELlhRjsg.png" /></figure><p>Disponibilizamos tambÃ©m nossa pipeline genÃ©rica pra escalar projetos Serverless em produÃ§Ã£o, Ã© bem simples de usar e evoluir a complexidade dos projetos caso necessÃ¡rio. Segue emÂ anexo.</p><p><a href="https://github.com/msfidelis/serverless-pipeline">msfidelis/serverless-pipeline</a></p><h3>10. Promova flexibilidade de ambientes</h3><p>Da mesma forma que costumamos criar diversos stages de desenvolvimento pra ter testes mais fiÃ©is antes de subir uma feature pra uma gama maior de clientes em aplicaÃ§Ãµes mais convencionais, as vezes serÃ¡ necessÃ¡rio aplicar isso no nosso processo de desenvolvimento da mesma forma. Utilizando um orquestrador como o Serverless Framework, fazer isso fica mais fÃ¡cil. Basta adaptar a sua pipeline de integraÃ§Ã£o e serÂ feliz!</p><pre>serverless deploy -v --stage homologacao</pre><h3>11. VariÃ¡veis deÂ ambiente</h3><p>Aproveitando a dica anterior, vocÃª vai precisar modificar sem duvida alguma algumas configuraÃ§Ãµes entre seu ambiente de stage, homolog, prod, nem que seja um apontamento de bancos, credenciais de ambientes de produÃ§Ã£o pra homologaÃ§Ã£o, limites, prefixos e uma sÃ©rie de coisas que a gente sÃ³ toma ciÃªncia depois que nossa aplicaÃ§Ã£o cresce.</p><p>Fazemos um load no serverless.yml dinamicamente com as variÃ¡veis de ambiente do stage em contexto, que passamos durante o deploy, noÂ caso:</p><pre>serverless deploy -v --stage develop</pre><p>Iremos carregar o arquivo configs/develop.yml com as variÃ¡veis desse ambiente. Um truque bem simples eÂ legal.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/aec61d7265343976ec4f0788d837ff4a/href">https://medium.com/media/aec61d7265343976ec4f0788d837ff4a/href</a></iframe><p>O AWS lambda oferece recursos de variÃ¡veis de ambiente e conseguimos trabalhar bem com esse recurso utilizando o<strong> Serverless Framework</strong>, porÃ©m as vezes nÃ£o Ã© muito seguro trabalhar com tokens, senhas, chaves de criptografia e deixar isso diretamente no painel AWS Lambda. Minha sugestÃ£o Ã© utilizar a biblioteca <strong>node-config</strong> ou o saudosoÂ <strong>dotenv.</strong></p><ul><li><a href="https://github.com/lorenwest/node-config">lorenwest/node-config</a></li><li><a href="https://github.com/motdotla/dotenv">GitHub - motdotla/dotenv: Loads environment variables from .env for nodejs projects.</a></li></ul><h3>12. Workers e o processamento desacoplado</h3><p>Ã‰ possÃ­vel escalar Workers utilizando AWS Lambda, porÃ©m isso nem sempre Ã© tÃ£o simples dependendo do caso. Podemos criar uma estrutura bÃ¡sica de worker que escuta uma fila do <strong>SQS</strong>, ou um <strong>Redis</strong>, <strong>Kafka</strong>, <strong>RabbitMQ</strong> e etc, porÃ©m como vocÃªs jÃ¡ devem saber nessa altura do campeonato, devemos trabalhar com timeout e memÃ³ria durante a execuÃ§Ã£o de uma funÃ§Ã£o lambda. No momento que escrevo este post, o mÃ¡ximo permitido no tempo de execuÃ§Ã£o Ã© 15Â minutos.</p><p>Minha pra evitar o timeout durante o processamento de muitos itens de forma assÃ­ncrona, minha sugestÃ£o Ã© sempre dividir o processamento de um lote de itens em lotes menores, e encaminhar esses lotes menores pra diferentes funÃ§Ãµes lambdas executarem em paralelo.</p><ol><li>Uma lambda Ã© encarregada de puxar os lotes de mensagens de uma fila qualquer;</li><li>Essa lambda divide os itens em pequenos lotes de 5, 10, 20, 40 itens, queÂ seja;</li><li>Essa lambda Ã© encarregada de evocar o processamento de uma nova lambda responsÃ¡vel por executar cada um desses pequenos lotes deÂ itens;</li></ol><h3>13. Monitore tudo, mas tudoÂ mesmo</h3><p>AplicaÃ§Ãµes Serverless herdam um pouco do cenÃ¡rio de microserviÃ§os tanto no aspecto positivo quanto no negativo, principalmente em questÃ£o de monitoramento. Ainda nÃ£o existe nenhuma soluÃ§Ã£o consolidada de APM pra serviÃ§os Serverless. Com o crescimento da aplicaÃ§Ã£o, problemas vÃ£o surgir, e vocÃª vai se dar conta de que as mÃ©tricas bÃ¡sicas que sÃ£o provisionadas de cara, como Invocations, numero de erros, concorrÃªncia e afins nÃ£o vÃ£o mais fazer tantoÂ sentido.</p><p>Existem algumas iniciativas do <strong>New Relic</strong> e <strong>Dashbird</strong> pra isso, mas quando o seu tracing precisar ser mais detalhado, vocÃª ainda vai precisar correr pra soluÃ§Ãµes mais granulares e vai perceber que sÃ£o as mesmas â€œfeijÃ£o com arrozâ€, como o <strong>CloudWatch</strong> e o <strong>X-Ray</strong> pra monitoramento distribuido.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EYM25V_drBPhe-W9eHzS7w.png" /></figure><p>Segue minhas alternativas:</p><ul><li><a href="https://docs.newrelic.com/docs/integrations/new-relic-integrations/getting-started/introduction-infrastructure-integrations"><strong>New Relic (Infraestructure Integration)</strong></a></li><li><a href="https://dashbird.io"><strong>Dashbird</strong></a></li><li><a href="https://aws.amazon.com/pt/cloudwatch/"><strong>Cloudwatch Logs + Dashboard</strong></a></li><li><a href="https://aws.amazon.com/pt/xray/"><strong>X-Ray Tracing</strong></a></li></ul><h4>Resumo</h4><ul><li>NÃ£o Ã© tÃ£o simples quanto te disseram;</li><li>Serverless nÃ£o mata o DevOps, muito pelo contrÃ¡rio, torna muito mais necessÃ¡ria a adoÃ§Ã£o das prÃ¡ticas eÂ cultura;</li><li>Todos os anos de aprendizado sobre qualidade de software podem ser reaproveitados;</li><li>Nem tudo precisa ser reinventado, existe um legado de ouro deixado por outros paradigmas de desenvolvimento;</li><li>O desenvolvedor precisa sim trabalhar localmente;</li><li>A seguranÃ§a deve ser levada em consideraÃ§Ã£o;</li><li>O multistage Ã© uma realidade;</li><li>Ainda Ã© necessÃ¡rio utilizar pipelines de entrega pra escalar seuÂ time;</li><li>Ainda sÃ£o necessÃ¡rias ferramentas pra garantir a qualidade doÂ cÃ³digo;</li><li>Qualidade do processo de desenvolvimento continua oÂ mesmo;</li><li>Monitore tudo, mas tudoÂ mesmo!</li></ul><p>Espero ter ajudado, vlw pessoal!Â :D</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=40e4e5e50470" width="1" height="1" alt="">
