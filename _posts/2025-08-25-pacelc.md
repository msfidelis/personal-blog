---
layout: post
image: assets/images/system-design/capa-databases.png
author: matheus
featured: false
published: true
categories: [ system-design, engineering, cloud ]
title: System Design - Teorema PACELC
---

Esse artigo é um complemento ao capítulo anterior sobre [ACID, BASE e Teorema CAP](/teorema-cap/), e apresenta uma evolução espiritual do modelo conceitual teórico do CAP e suas críticas que foram construídas com a evolução dos sistemas distribuídos e seus componentes. 

# O Teorema PACELC

O Teorema PACELC foi proposto por Daniel Abadi em 2010 pela Universidade de Yale, e ele nos ajuda a entender sistemas distribuídos um pouco além do proposto pelo Teorema CAP. O Teorema CAP, como já visto, nos propõe que **um sistema mediante a uma partição de rede precisa escolher a consistência e a disponibilidade**. Esse modelo foi, e ainda é extremamente importante para nortear decisões arquiteturais e de engenharia em diversos contextos, mas ainda deixa algumas lacunas conceituais em sistemas modernos, principalmente sobre o comportamento do sistema quando consideramos "Partition Tolerance", por exemplo: **O que aconteceria com esse determinado sistema quando não houver falhas de rede?**.

![Partição de Rede](/assets/images/system-design/pacelc-partition-sync.drawio.png)

O PACELC nos ajuda a entender esse modelo de databases distribuídos em um outro cenário: **"o que acontece quando não há falhas de rede e particionamento entre os nós do meu sistema?"** **Eu consigo operar em dois diferentes níveis de consistência** nesses cenários se preciso? **O que o meu sistema precisa priorizar quando está funcionando corretamente?** **O que ele precisa priorizar quando ocorre um particionamento entre os nós?**



# Teorema PACELC vs Teorema CAP

Como embasado anteriormente, o teorema cap diz que **quando ocorre uma Partição de Rede (P) entre os nodes do meu sistema, eu preciso buscar uma solução que escolha entre Consistência (C), ou Disponibilidade (A)**. Isso é muito útil para escolha de tecnologias que considerem entre esses dois tradeoffs, mas sobra o requisito não funcional de como meu sistema deve operar quando essa partição não existe. 

![PACELC](/assets/images/system-design/pacelc.drawio.png)

O PACELC funciona como uma extensão do CAP, e propõe o racional de que **se houver partição (P), devemos escolher entre Disponibilidade (A) e Consistência (C)**; **Else (E)**, ou seja, **se não houver partição**, **escolhemos entre latência (L) e consistência (C)**. O teorema mostra que, mesmo em condições normais do sistema sem partições, você ainda precisa tomar decisões difíceis na escolha da arquitetura. OU prioriza a garantia de uma consistência forte e paga o preço de mais latência para viabilizar esse cenário, ou abre mão de maiores níveis de consistência e maiores tempos de sincronia para reduzir a latência e o tempo de resposta das operações.

**Em momentos de falha, decidimos entre disponibilidade e consistência**. Fora deles, **optamos entre consistência forte, que pode custar latência**, e consistência eventual, que **otimiza a performance das operações** mas **sem garantias de consistência**.

Esse racional coloca o modelo muito mais próximo da realidade de sistemas modernos, onde possuimos redes geograficamente distribuídas, [replicação de dados]() e [sharding e particionamento.]() 

Imagine um banco de dados global. Se ele quiser garantir que todas as réplicas do mundo estejam sempre sincronizadas antes de confirmar uma operação (consistência forte), cada escrita vai ser mais lenta por causa da latência de rede. Já se ele aceitar consistência eventual, pode responder mais rápido, mas corre o risco de o usuário no Brasil ver um dado diferente do usuário na Espanha por algum tempo.

Em resumo, ambos os teoremas não são completamente excludentes, são complementares. O PACELC analisa padrões de comportamentos em sistemas distribuídos nos cenários do CAP, mas somente onde existem partições, como os cenários CP (Consistency e Partition Tolerance e AP (Availability e Partition Tolerance). 

<br>

# Aplicações do PACELC

O Teorema PACELC se tornou uma forma de classificar sistemas distribuídos e suas bases de dados. Um exemplo nominal, o DynamoDB é conhecido como PA/EL (prefere disponibilidade durante partições e latência baixa em condições normais). Já o Google Spanner é PC/EC (prefere consistência tanto durante partições quanto no dia a dia, aceitando pagar o preço da latência). Dentro dele, assim como no CAP que consideramos AP, AC, CP, AC, podemos ter diferentes classificações dos databases em PACELC, como PA/EL, PC/EL, PA/EC, PC,EC. 

## PA/EL (On Partition, Availability; Else, Latency) - OK

![PA/EL](/assets/images/system-design/pacelc-pael.drawio.png)

O modelo PA/EL descreve um sistema em que no seu funcionalmento normal, sem uma partição de rede, ele prioriza a latencia ao invés da consistencia. Esse tipo de sistema priorizam a baixa latência das operações ao invés de uma consistência forte. ELSE; Quando ocorre uma partição de rede, o mesmo prioriza a disponibilidade ao invés da consistencia novamente. Em outras palavras, agravam a consistência eventual, onde todos os nodes independentes do rompimento da partição continuam respondendo as requisições, mesmo que todas as replicas não estejam em sincronia da replicação. 

![PA/EL - Error](/assets/images/system-design/pael-error.drawio.png)

Esses databases são projetados para oferecerem uma experiência de performance alta das operações de escrita de forma resiliente, mas aceitam que diferentes usuários possam ver versões ligeiramente diferentes dos dados por algum tempo até a partição ser resolvida. É o caso de bancos como DynamoDB e Cassandra, usados em cenários de grande escala, onde performance global e disponibilidade são mais importantes que consistência absoluta.

## PC/EL (On Partition, Consistency; Else, Latency) - OK

![PC/EL](/assets/images/system-design/pc-el.drawig.png)

No modelo PC/EL temos a descrição de sistemas que em seu funcionamento normal, prioriza latência e alto throughput a custo da consistencia. Ele diminui o nível da consistencia operacional para manter os tempos de resposta altos, otimizados para escrita. ELSE; Em caso de particionamento o sistema opera priorizando consistencia.  Isso significa que, em uma situação de falha, o sistema pode ficar indisponivel até que o cluster recupere o seu consenso e volte a operar. 

![PC/EL - Error](/assets/images/system-design/pc-el-error.drawio.png)

É uma escolha intermediária, onde os sistemas em questão não possui soluções de resolução de conflitos confiável com grandes volumes de dados, apenas com o fluxo transacional previsto, então é melhor indisponibilizar o serviço do que ter que lidar com uma porcentagem de dados que por ventura não vão se tornar consistentes em algum momento. É interessante quando a consistência mínima durante falhas é inegociável, mas durante a operação normal prioriza alto desempenho nas operações de escrita e leitura. Ele aceita consistencia eventual, porém em caso de falha dos nós, escolhe ficar totalmente inoperante. Pode trabalhar com consistencia eventual, mas somente se todos os nodes estiverem disponíveis, exigindo processos de healthchecks e heartbeats entre ambos continuamente para chegar seus status antes de realizarem as operações. 

## PA/EC (On Partition, Availability; Else, Consistency)

![PA/EC](/assets/images/system-design/pa-ec.drawio.png)

O Modelo PA/EC descreve sistemas que em tempos de operações normais, prioriza a consitencia forte, garantindo que todas as replicas do sistemas tenham a mesma versão do dado sempre. ELSE; em falhas ou particionamentos de rede, prioriza a disponibilidade, aceitando receber escrita e leitura mesmo que existam divergencias temporarias. 

![PA/EC Error](/assets/images/system-design/pa-ec-error.drawio.png)

Normalmente esse sistema conta com algoritmos complexos de [CRDT's](/replicacao/), ou Conflict Free Replicated Data Types, algoritmos que faz gestão de conflitos entre diferentes atualizações de um dado em nodes distribuídos.  Esse modelo é menos comum, mas pode aparecer em contextos híbridos de microserviços, onde a experiência do usuário não pode parar mesmo com falhas parciais, mas a regra de negócio e a criticidade operacional exigem que, quando a rede está saudável, todos os dados fiquem rigorosamente sincronizados. Assume a consistencia eventual como um fallback da consistencia forte em ultimo caso. 


## PC/EC (On Partition, Consistency; Else, Consistency) - OK

![PC/EC](/assets/images/system-design/PC-EC.drawio.png)

O modelo PC/EC descreve sistemas que são mais conservadores com a consistencia dos seus dados. Durante a partição, o sistema escolhe a consistencia em vez de disponibilidade, assumindo que é melhor falhar do que estar eventualmente consistente em algum nível. 

![PC/EC](/assets/images/system-design/PE-EC-Partition.drawio.png)

ELSE; em operações normais, também prioriza consistencia ao invés de latência, aceitando um custo maior de tempo de resposta em troca da garantia da ultima versão do dado disponível em todos os nós. Esse comportamento é mais comum em sistemas em que a precisão dos dados é a qualidade mais importante. É a escolha natural para sistemas bancários, coordenação de clusters e transações críticas, onde ver dados incorretos por alguns milissegundos pode gerar prejuízos enormes. Pode ser encontrado em bancos SQL tradicionais, no etcd e também em bancos transacionais geograficamente distribuídos como Google Spanner. 

<br>

### Comparações do PACELC 


| Sistema / Banco de Dados | PAC (durante partição)                                                    | ELC (sem partição)                                                                 | Classificação        | Observação                                                                                         |
|---------------------------|--------------------------------------------------------------------------|-------------------------------------------------------------------------------------|----------------------|---------------------------------------------------------------------------------------------------|
| **Amazon DynamoDB**       | **A** (disponibilidade)                                                  | **L** (baixa latência, consistência eventual por padrão)                            | **PA/EL**            | Eventual consistency como default, mas suporta “strong reads” opcionais.                          |
| **Cassandra**             | **A** (disponibilidade)                                                  | **L** (baixa latência, consistência eventual por padrão)                            | **PA/EL**            | Modelo baseado no Dynamo, otimizado para disponibilidade e baixa latência global.                 |
| **MongoDB**               | **A** (se configurado com `w=1`) ou **C** (com majority write concern)   | **L** (eventual consistency em réplicas secundárias)                                | **PA/EL** ou **PC/EL** | Flexível; o trade-off depende do write concern e read concern.                                     |
| **Google Spanner**        | **C** (consistência forte global)                                        | **C** (mesmo sem partição, prioriza consistência)                                   | **PC/EC**            | Usa TrueTime para garantir consistência serializável global, com custo de latência.                |
| **Azure Cosmos DB**       | **A** (disponibilidade)                                                  | **L/C** (configurável: eventual, bounded staleness, session, consistent prefix, strong) | **PA/ELC**           | Oferece 5 níveis de consistência configuráveis.                                                    |
| **Apache Kafka**          | **A** (disponibilidade)                                                  | **L** (prioriza throughput e baixa latência)                                       | **PA/EL**            | Garantias de consistência são fracas; foco em disponibilidade e velocidade.                        |
| **Etcd**                  | **C** (consistência forte)                                               | **C** (consistência forte)                                                          | **PC/EC**            | Voltado para consistência forte, usado em sistemas críticos de coordenação.                        |
| **ZooKeeper**             | **C** (consistência forte)                                               | **C** (consistência forte)                                                          | **PC/EC**            | Voltado para consistência forte, usado em sistemas críticos de coordenação.                        |
| **CockroachDB**           | **C** (prioriza consistência em partições)                              | **C** (consistência forte via consenso Raft)                                        | **PC/EC**            | Inspirado no Spanner, mantém consistência global em troca de latência mais alta.      
| **Redis em Cluster Mode**         | **A** (disponibilidade, pode perder dados em falhas)                     | **L** (baixa latência com replicação assíncrona)                                    | **PA/EL**            | Focado em velocidade; consistência forte não é garantida em partições ou failover.   
| **Amazon RDS (Multi-AZ)** | **C** (replicação síncrona entre zonas, prioriza consistência)           | **C** (dados consistentes entre réplicas antes de confirmar)                        | **PC/EC**            | Designado para workloads transacionais, garantindo consistência e durabilidade.                    |



<br>

### Referências

[Consistency Tradeoffs in Modern Distributed Database System Design](https://www.cs.umd.edu/~abadi/papers/abadi-pacelc.pdf)

[PACELC design principle](https://en.wikipedia.org/wiki/PACELC_design_principle)

[PACELC: A extensão do Teorema CAP](https://emergingcode.substack.com/p/pacelc-a-extensao-do-teorema-cap)

[PACELC Theorem](https://www.scylladb.com/glossary/pacelc-theorem/)

[PACELC Theorem Explained: Distributed Systems Series](https://medium.com/distributed-systems-series/pacelc-theorem-explained-distributed-systems-series-9c509febb8f8)

[System Design Interview Basics: CAP vs. PACELC](https://www.designgurus.io/blog/system-design-interview-basics-cap-vs-pacelc)

[PACELC Theorem](https://www.geeksforgeeks.org/operating-systems/pacelc-theorem/)

[PACELC Theorem & Distributed Databases](https://ritesh-kapoor.medium.com/pacelc-theorem-and-distributed-databases-301d971deda3)

[Understanding Eventual Consistency in DynamoDB](https://www.alexdebrie.com/posts/dynamodb-eventual-consistency/)