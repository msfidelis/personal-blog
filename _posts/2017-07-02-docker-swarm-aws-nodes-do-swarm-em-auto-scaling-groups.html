---
layout: post
title: 'Docker Swarm & AWS :: Nodes do Swarm em Auto Scaling Groups!'
canonical_url: https://medium.com/@fidelissauro/docker-swarm-aws-nodes-do-swarm-em-autoscaling-groups-bb1a759882c5?source=rss-fc2fda5e9bc2------2
---

<figure><img alt="" src="https://cdn-images-1.medium.com/max/711/1*2CX2ROjJK5SPGmHh3D4iLQ.png" /></figure><p>Neste post criamos várias paradinhas utilizando o <strong>Docker Swarm</strong> na <strong>Amazon AWS</strong>. Subimos um cluster completo dentro de uma VPC de uma maneira bem simplista com o <strong>Docker Machine</strong> no ultimo post sobre, e também um cluster local utilizando <strong>Virtualbox</strong>. Eles são bem legais, segue link:</p><ul><li><a href="https://medium.com/@fidelissauro/docker-swarm-quickstart-do-seu-cluster-local-com-docker-machine-e-virtualbox-44d4096deae">Docker Swarm 01 — Quickstart do seu Cluster Local com Docker-Machine e Virtualbox.</a></li><li><a href="https://medium.com/@fidelissauro/docker-swarm-02-quickstart-do-seu-cluster-de-ec2-na-amazon-aws-com-docker-1394d365cb04">Docker Swarm 02— Quickstart do seu Cluster de EC2 na Amazon AWS com Docker.</a></li></ul><p>Neste post não vamos utilizar o <strong>Docker Machine</strong> devido a algumas limitações que você poderá encontrar futuramente. Nós vamos utilizar recursos da AWS como <strong>Launch Configurations</strong>, <strong>Load Balances</strong>, <strong>Auto Scaling Groups</strong>, <strong>AMI’s</strong> e etc. Tudo bem mastigado pra você conseguir subir nodes em auto scaling sem muitos problemas.</p><p><em>Caso encontre algo, deixe aqui nos comentários pra gente resolver junto.</em></p><p>Vamos lá!</p><h3>Configurações iniciais</h3><p>Precisamos preparar um pouco do terreno antes de implementar nosso cluster. Esses recursos são bem simples de resolver.</p><ol><li><strong>Criando uma Key Pair.</strong></li></ol><ul><li>Vamos no painel de EC2 &gt; <strong>Key Pairs &gt; Create Key Pair</strong></li><li>Colocamos um nome e salvamos. Bem simples! O Download será iniciado, certifique-se de guardar ela muito bem.</li><li>Você pode reaproveitar outras se quiser. Sem problemas.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*d-EPgwTJn1MFoGZRtuzkFg.png" /></figure><p><strong>2. Criando uma VPC</strong></p><p>Para criar uma VPC é bem simples:</p><ul><li>Vamos até o painel da VPC e clicar em <strong>Create VPC</strong>.</li><li>Nosso assistente vai nos guiar até onde for possível da primeira vez. Caso você já tenha uma VPC criada, será necessário algumas configurações a mais.</li><li>Deixei tudo mastigado neste artigo. É só ver as primeiras partes e voltar aqui :P</li></ul><p><a href="https://medium.com/@fidelissauro/docker-swarm-02-quickstart-do-seu-cluster-de-ec2-na-amazon-aws-com-docker-1394d365cb04">Docker Swarm 02— Quickstart do seu Cluster de EC2 na Amazon AWS com Docker.</a></p><p><strong>3. Criando um Security Group</strong></p><p>Vamos criar um <strong>Security Group</strong> liberando:</p><ul><li>A porta 22 para o mundo, pois vamos nos autenticar com nossa Key gerada. O que futuramente você pode limitar para o IP da sua empresa e etc.</li><li>A porta 80 para o mundo. Pois nossa aplicação vai atender aqui.</li><li>Todas as portas liberadas para o security group que acabamos de criar, no caso todas as máquinas do nosso cluster de Swarm. Isso também deve ser revisto futuramente.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*G_6nb2hUsnjFqm7H_zHKqA.png" /></figure><h3>Iniciando nossa primeira instância para a AMI</h3><p>Vamos fazer o café com leite de todo o ecossistema da AWS, lançar uma EC2 dentro da nossa VPC que acabamos de criar. Ela vai ser nosso ponto de configuração inicial, onde vamos gerar nossa AMI. Para isso, vamos lançar uma instância limpa e instalar somente o Docker nela. O resto da mágica vai acontecer nos próximos passos.</p><p>Para essa demo, decidi utilizar o <strong>Amazon Linux</strong>, pelo simples motivo de já vir com vários repositórios configurados, incluindo o do <strong>Docker CE</strong>, isso já nos faz ganhar um tempinho.</p><ol><li>Vá no painel de EC2, e selecione <strong>Launch Instance</strong>. Selecione o <strong>Amazon Linux</strong> e vambora.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*T6h0UGIRLFbbNP1Y88vrKw.png" /></figure><p>2. Atenção ao <strong>Step 3: Configure Instance Details</strong>, certifique-se de que vamos lançar instância dentro da nossa VPC, na nossa <strong>Subnet</strong> que criamos e que a opção <strong>Auto-assign Public IP </strong>está marcada como <strong>Enabled</strong>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EmOD01eLnLtKG94xFFmozQ.png" /></figure><p>3. Escolha o <strong>Security Group</strong> que acabamos de criar. No nosso caso, o “<strong>Swarm</strong>”.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*G_6nb2hUsnjFqm7H_zHKqA.png" /></figure><p>4. Escolha também a chave SSH que geramos anteriormente e lance a instância. Aguarde a mesma ser criada e conecte-es nela para iniciarmos a brincadeira de gerar a AMI.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*L_WeeQl4uRN2ECuH5vK3kA.png" /></figure><p>Aguarde a mesma terminar de ser criada e… Tá pronto o sorvetinho!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/830/1*gdcpTZdvzLehIiy4D25_Qw.png" /></figure><h3>Instalando o Docker e as dependências iniciais</h3><p>Agora vamos adicionar alguns scripts do shutdown e reboot na máquina e instalar algumas dependências importantes, como o Docker (dã). Para conectar na máquina, vamos para o terminal. Vamos conectar com o usuário default do Amazon Linux, o ec2-user apontando nossa chave swarm.pem.</p><pre>$ ssh ec2-user@ip-externo-da-maquiba -i swarm.pem</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*MzvwEfrVnYJsv9PykAeLjw.png" /></figure><p>Vamos atualizar a máquina e instalar o <strong>Docker CE</strong></p><pre>$ sudo yum update<br>$ sudo yum install docker -y</pre><p>Agora vamos inicializar o serviço do Docker</p><pre>$ sudo service docker start</pre><p><strong>Script de Shutdown e Reboot</strong></p><p>Para que as máquinas saiam do cluster quando desligarem, precisaremos customizar os runlevels 0 e 6, ou halt e reboot respectivamente. Para isso vamos criar um script que vai rodar nesses dois cenários.</p><pre>$ vim /etc/rc.d/rc0.d/01SWARMleave</pre><p>E colar o conteúdo:</p><pre>#!/bin/bash</pre><pre>docker swarm leave --force</pre><p>Agora salve. Esse mini script vai executar uma tarefa muito simples, indicar para o swarm que essa máquina não vai mais pertencer ao cluster. Agora ela pode morrer sem nenhum problema. Isso impede de que seja criada muita sujeita e gerar algum tipo de indisponibilidade.</p><p>Agora vamos dar permissão de execução para o script e criar um link simbólico para a pasta de scripts de reboot da máquina, o rc6.d</p><pre>$ sudo chmod +x /etc/rc.d/rc0.d/01SWARMleave<br>$ sudo ln -s /etc/rc.d/rc0.d/01SWARMleave /etc/rc.d/rc6.d/01SWARMleave</pre><p>Pronto, agora é só desligar a máquina! Acredite ou não, isso é todo o necessário para criar um cluster de Swarm simples, porém escalável e sustentável!</p><pre>$ sudo halt</pre><h3>Gerando nossa AMI</h3><p>Um dos recursos mais legais de todas as nuvens provedoras de IaaS são as Imagens, ou como chamamos, as AMI’s. Elas são imagens base customizadas que podemos utilizar para lançar aplicações pré configuradas, nos poupando bastante tempo. Nesse caso, vamos gerar uma a partir da máquina que acabamos de criar (e desligar), desse modo sempre que lançarmos uma instância, ela já vai vir com o Docker instalado e com nosso scripts de desligamento no lugar certo. Vamos lá!</p><p>No painel de <strong>EC2</strong>, vamos selecionar nossa máquina desligada.</p><ol><li>Em <strong>Actions</strong> &gt; <strong>Image</strong>, selecione a opção <strong>Create Image</strong></li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*nxozZz99oFyinUxYeptjTA.png" /></figure><p>2. Agora definir um nome para a imagem e ajustar coisas simples, como tamanho de volumes e etc. Em seguida clique em Create Image. Nesse momento um pedido de criação da imagem vai ser gerado. A Amazon não costuma demorar muito pra gerar.</p><p>Para acompanhar, você pode ir no <strong>Painel de EC2</strong> &gt; <strong>Images</strong> &gt; AMI’s</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*7mlHZVbrDYUFZfP-Uzp69A.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*csjcbFT2phZY792JtKCVEw.png" /></figure><h3>Criando nosso Node Manager</h3><p>O ultimo passo antes de criar nossa política de <strong>Auto Scaling</strong>, <strong>Load Balances</strong> e etc, vamos iniciar uma máquina a partir daquela imagem que acabamos de gerar para ser nosso Manager. (Ps: Pode ser aquela mesma que acabamos de desligar se você estiver com preguiça, só ligar ela de novo ;D).</p><ol><li>No painel de EC2, vamos selecionar Launch Instance mais uma vez! Mas agora ao invés de selecionar uma AMI da Amazon como fizemos com o <strong>Amazon Linux</strong>, vamos lançar uma que está na aba <strong>My AMIs</strong>, no caso a <strong>Swarm Node</strong> que acabamos de criar!</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*waHfOEvqGS3FrZsq4oWOjg.png" /></figure><p>Agora o processo é “mais do mesmo”. Escolha o tamanho, disco e não esqueça daquela configuração básica de rede e VPC que fizemos da primeira vez. Tem que estar com o <strong>Auto-assign Public IP</strong> como <strong>Enabled</strong> e ela deve ser lançada <strong>dentro da nossa VPC</strong>. No final, escolha nossa chave convencional <strong>swarm.pem </strong>e vambora!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*W901PId8d83ZN6ZUkPKj5w.png" /></figure><p>Vamos conectar via SSH nessa nova instância e iniciar nosso cluster.</p><pre>$ ssh ec2-user@ip-externo-da-maquiba -i swarm.pem<br>$ sudo docker swarm init --advertise-addr eth0</pre><p>O console irá nos cuspir uma saída parecida com essa e nos dar um comando já mastigado com o Token de acesso para ingressar novos nodes Guarde bem essa string que ele vai te gerar. Ela vai ser bem importante futuramente.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Whke8jNaKUXoqCvAAhVMUw.png" /></figure><p><strong>Launch Configurations e Auto Scaling Groups</strong></p><p><strong>Launch Configuration </strong>— As configurações inicias das máquinas.</p><p>No Painel de EC2, vá até o menu <strong>Auto Scaling</strong> &gt; <strong>Launch Configurations</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*2594AG2mwzIxoioRvXgAYQ.png" /></figure><p>Seleciona a opção Create a <strong>Auto Scaling Group</strong> &gt; <strong>Create a Launch Configurations</strong> &gt; <strong>My AMIs</strong> e selecione nossa AMI, a Swarm Node!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*AMS3I6r07i0mr4JA7BxdRA.png" /></figure><p>Agora volta ao nosso “Mais do mesmo”, faça o mesmo processo de sempre tomando cuidado com as mesmas coisas de sempre, de <strong>VPC</strong>, <strong>Security Groups</strong>, <strong>Tamanho das máquinas</strong> e etc.</p><p><strong>Atenção especial:</strong></p><ol><li>Em <strong>3. Configure details </strong>vá em Advanced Details e selecione a opção <strong>Assign a public IP address to every instance</strong>. Dessa forma vamos poder criar hosts prontos para a Web. Você pode optar por não fazer isso e criar um load balance único para todas as instâncias futuramente. Mas como aqui é só pra fins demonstrativos, vamos deixar mais fácil a manutenção caso dê algum problema. Na vida real, deixe só pro load balance fazer sua mágica!</li><li>Ainda em <strong>Configure details </strong>vamos procurar o campo User data. Esse campo podemos colocar um script que vai ser executado no iniciar da máquina. Aqui vamos colar aquela super string que o node master nos gerou anteriormente. Aqui está tudo o pulo do gato, quando a máquina iniciar, ela automaticamente vai ingressar no nosso cluster ;)</li></ol><p>Nosso User data vai ficar parecido com esse, troque somente as informações do docker swarm join:</p><pre>#!/bin/bash</pre><pre>sudo yum update -y<br>sudo yum install htop<br>sudo systemctl enable docker.service</pre><pre>sudo docker swarm join  --token SWMTKN-1-2tcrqcot4sctwi08l53e6vgq9py05bwjc64yskzwyfagy8qzwg-92rqjoi3tzuzm9x8v8u6sni7u 10.0.0.184:2377</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*4Eh2gkeQ6Qra-KBEcHFr6w.png" /></figure><p><strong>Auto Scaling Group</strong></p><p>Agora vamos criar um grupo de Auto Scaling a partir dessas configurações base que criamos. Basicamente vamos criar um grupo que vai iniciar e matar máquinas com as especificações que criamos no Launch Configurations.</p><ol><li>Vá em EC2 &gt; <strong>Auto Scaling</strong> &gt; <strong>Auto Scaling Groups</strong></li><li>No Assistente, clique em <strong>Create Auto Scaling Group</strong> e selecione a <strong>Launch Configuration</strong> que acabamos de criar.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GtNKYqgv_vu11UHffmPPCw.png" /></figure><p>3. No próximo Step, defina um nome para o grupo, selecione a nossa VPC e nossa Subnet padrão. Inicialmente, podemos avançar até o final agora sem nenhum problema. Mais pra frente vamos brincar mais.</p><p>4. Após criá-lo, vamos em Edit. Aqui vamos definir algo bem importante: As quantidades de instâncias <strong>Min</strong>, <strong>Max</strong> e <strong>Desired</strong>.</p><ul><li>Min: 1</li><li>Max: 10</li><li>Desired: 1</li></ul><p>Podemos ver agora que uma instância foi lançada no painel de EC2. Para saber se deu certo, vamos conectar via SSH novamente no nosso Node Master e listar os nodes ativos. É pra ter dois nodes!</p><pre>$ docker node ls </pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*hAT6ck_PR9_u0f9P2OPtzg.png" /></figure><p><strong>Lançando nosso primeiro service</strong></p><p>Vamos criar um service de API. Eu tenho uma imagem customizada pra esses tipos de demos de Swarm. No nosso Manager, vamos executar:</p><pre>$ sudo docker service create \<br>  --name=api \<br>  --publish=80:80/tcp \<br>  --constraint=node.role==worker  \<br>  msfidelis/example-api</pre><p>Desse modo nos restringimos a lançar esse serviço apenas em hosts com role de Worker.</p><p>Para monitorar onde estão nossos containers e escalar os mesmos, podemos utilizar:</p><pre>$ docker service ps api</pre><pre>ID            NAME   IMAGE                         NODE          DESIRED STATE  CURRENT STATE               ERROR  PORTS<br>j4porh6ebv4a  api.3  msfidelis/example-api:latest  ip-10-0-0-59  Running        Running about a minute ago</pre><p>E para escalar os mesmos em quantidade:</p><pre>$ docker service scale api=10</pre><pre>api scaled to 10</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GPgBdAwVPvbe5dM7NYKlTA.png" /></figure><p>Agora acesse várias vezes:</p><pre>http://ip-do-worker/whoami</pre><p>O resultado é o hostname do container, e ele deverá responder randomicamente conforme o loadbalance do Docker distribui a carga entre os nossos containers.</p><blockquote>Mas Matheus, beleza… Legal. Mas eu só tenho uma máquina, como eu faço pra testar esse auto scaling group?</blockquote><p>Fácil, meu amigo! Vamos lançar mais uma instância lá nos nosso auto scaling groups. No nosso Group “<strong>Swarm Nodes</strong>”, vamos clicar em Edit e mudar o <strong>Desired</strong> para 2. Assim lançamos mais uma instância!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DlmoglJlzzizmzDME0XHhg.png" /></figure><p>Agora vamos aguardar uns instantes para ela subir e se integrar ao cluster. Podemos acompanhar isso no manager, com o comando</p><pre>$ docker node ls</pre><p>Podemos monitorar de novo a distribuição dos containers dentro do cluster para visualizar a nova distribuição de containers, usando:</p><pre>$ docker service ps api </pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*jasAsyUWiKoLnMvs9BJ1pQ.png" /></figure><p>Note que agora eles estão distribuídos entre os workers para aliviar a carga!</p><p><strong>Dica especial:</strong></p><p>Existe um serviço de monitoramento do Cluster de Swarm chamado visualizer. Eu te aconselho a ir no seu <strong>Security Group</strong> e liberar a porta 3000 para o seu IP atual antes de lançar esse service.</p><p>Nesse caso, eu vou lançar o service com a role Manager, para que ele não vá parar nos nossos Workers.</p><pre>$ docker service create \<br>  --name=monitor \<br>  --publish=3000:8080/tcp \<br>  --constraint=node.role==manager \<br>  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \<br>  dockersamples/visualizer</pre><p>Agora acesse:</p><pre>http://ip-do-manager:3000</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*I-M0wJWsW4NZDjQpDL2TFA.png" /></figure><p>Pra acompanhar vamos subir mais uma máquina no Desired. Vamos colocar ele pra 3 e acompanhar por aqui pra ver no que dá!</p><p><strong>Load Balancer</strong></p><ol><li>Em EC2 &gt; <strong>Load Balancing</strong> &gt; <strong>Load Balancers</strong>, selecione a Opção <strong>Create Load Balancer</strong>.</li><li>Como estamos utilizando somente uma subnet, vamos utilizar o <strong>Classic Load Balancer</strong>. Em produção, talvez seja interessante utilizar o <strong>Application Load Balancer</strong> para balancear o tráfego entre diversas zonas.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*nLf6tsyef8bt6KG86BSSpQ.png" /></figure><p>3. Adicione a Subnet que criamos na zona e.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TCi4h6kh3UYw6b-zsAgXvw.png" /></figure><p>4. Anexe o Security Group do Swam no Health Check, aponte o Patch / e a porta para 80.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*VHv0xM4Bu8qvVszVfxqYOA.png" /></figure><p>Em seguida passe reto por todas as opções e crie o Load Balance sem adicionar nenhuma instancia. Vamos fazer isso no Auto Scaling Group :)</p><p>5. No painel de EC2, vamos até o Auto Scaling Group novamente. Clique em <strong>Edit</strong> e na opção <strong>Load Balancers</strong>, adicione o que acabamos de criar e salve! Elas não vão automaticamente entrar no Load Balance, somente as novas instâncias vão ingressar no mesmo. Temos duas opções:</p><p><strong>5.1 Matar todas as instâncias e subir novamente.</strong></p><p>Em desired, selecione 0. Após todas morrerem, selecione o melhor numero de instâncias pra você. Ou vá para o painel e desligue todas.</p><p><strong>5.2 Ingressar manualmente</strong></p><p>Indo em <strong>Loab Balances</strong> &gt; Selecione nosso Load Balance &gt; <strong>Instances</strong> &gt; <strong>Edit Instances</strong> e selecione as novas que acabamos de criar</p><p>Agora, acesse:</p><pre>http://dns-do-load-balance/whoami</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*SyWCqo6B09VK9WR2nOStyg.png" /></figure><h3>Dica esperta: Auto Rebalance automático de Containers</h3><p>Até então, na versão mais recente, o Swarm não possui uma feature de Rebalance de containers quando um node novo ingressa no Cluster, o que torna problemático de se utilizar no nosso cenário de auto scaling e load balancing. Temos duas opções para resolver isso:</p><ol><li><strong>Crontab para fazer rebalance nos containers.</strong></li></ol><p>Para isso, vamos criar um shell que roda de 5 em 5 minutos reorganizando os containers dentro dos nodes disponíveis no nosso cluster, que vai nos possibilitar trabalhar com load balance. Quando sair a solução pra essa Issue, eu posto aqui e atualizo pra vocês :). O link tá <a href="https://github.com/moby/moby/issues/24103"><strong>aqui</strong></a> pra quem quiser dar uma força.</p><pre>vim /etc/crontab</pre><p>Adicione a linha:</p><pre>*/5 * * * * docker service ls -q &gt; dkr_svcs &amp;&amp; for i in `cat dkr_svcs`; do docker service update &quot;$i&quot; --force ; done</pre><p>Isso funciona, mas nos faz perder algumas coisas:</p><ul><li>Caso seja necessário um rollback de versão, pode ser problemático. Pois de 5 em 5 minutos vai rolar um update para a versão mais recente sempre.</li><li>Caso existam mais máquinas que containers ingressados, máquinas vão poder ficar vazias. Isso te obriga a sempre ter mais containers rodando do que o seu possível número de máquinas.</li></ul><p><strong>2. Usando o Global Mode</strong></p><p>O Docker Swarm possui uma opção de modo Global de um service. Isso significa que podemos especificar que todos os nodes vão ter uma replica desse container, mas APENAS UMA.</p><pre>$ sudo docker service create \<br>  --name=api \<br>  --publish=80:80/tcp \<br>  --constraint=node.role==worker  \<br> <strong> --mode=global \</strong><br>  msfidelis/example-api</pre><p>Essa solução é boa. Mas caso você realmente necessite de vários containers, isso pode ser um problema. Eu prefiro a primeira solução. Espero que essa issue seja respondida pela comunidade o mais rápido possível :).</p><h3>FAQ: Coisas que você (talvez) não considerou, mas poderá te causar problemas no futuro.</h3><blockquote>Matheus, a AWS costuma fazer manutenções programadas e não posso confiar apenas em um Manager. Se o Manager cair, meu cluster já era???</blockquote><p>Seu cluster vai sempre responder. Mas o ideal é ter de 1, 3 ou 5 Hosts manager rodando de redundância no seu cluster. Caso você precise reiniciar, desligar ou criar uma redundância no seu cluster, você pode:</p><ol><li><strong>Promover um ou mais nodes do cluster para manager</strong><br>Para promover basta saber o hostname do Node</li></ol><pre>$ docker node ls # Listar os nodes<br>$ docker node promote hostname</pre><p>Não se esqueça de tirar esse node do Load Balance ;).</p><p><strong>2. Criar uma nova instância e ingressá-la como node Manager.</strong></p><p>Aqui vamos fazer o ingress normal, e depois promovê-la mais tarde para Manager usando o mesmo processo anterior.</p><p>Espero ter ajudado!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=bb1a759882c5" width="1" height="1" alt="">
